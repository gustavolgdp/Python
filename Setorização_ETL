# -*- coding: utf-8 -*-
r"""
ETL: Delta -> Parquet (FATO_SETORIZACAO_30MIN), com Polars (vetorizado) e multithread.

- Lê Delta em: C:\Output\delta\fato_setorizacao_30min
- Recalcula DATA_RELATIVA (semana começa em 01/jan do ano):
    * DATA_RELATIVA = n + DDD + HHMM, ex.: 1QUA0000
- Mantém: ts, DATA_RELATIVA, Q_CTR, Q_ASS, Q_COOR, Q_SPVS, TURNO
- Salva Parquet em: C:\Output\parquet\fato_setorizacao_30min.parquet
"""

import os
import sys
from tqdm import tqdm

# ---------- CONFIG ----------
DELTA_DIR   = r"C:\Output\delta\fato_setorizacao_30min"
OUT_PARQUET = r"C:\Output\parquet\fato_setorizacao_30min.parquet"

# os.environ["POLARS_MAX_THREADS"] = "8"  # (opcional) limitar threads

# ---------- IMPORTS ----------
try:
    import polars as pl
except Exception as e:
    sys.exit(f"Erro ao importar polars: {e}\nInstale com: pip install polars")

try:
    from deltalake import DeltaTable
except Exception as e:
    sys.exit(f"Erro ao importar deltalake: {e}\nInstale com: pip install deltalake")

try:
    import pyarrow as pa  # noqa
except Exception as e:
    sys.exit(f"Erro ao importar pyarrow: {e}\nInstale com: pip install pyarrow")

# ---------- VALID ----------
if not (os.path.isdir(DELTA_DIR) and os.path.isdir(os.path.join(DELTA_DIR, "_delta_log"))):
    sys.exit("Caminho Delta inválido (verifique se existe e se contém a pasta _delta_log).")

NEEDED_COLS = {"ts", "Q_CTR", "Q_ASS", "Q_COOR", "Q_SPVS", "TURNO"}
WEEKDAY_ABBR = ["SEG", "TER", "QUA", "QUI", "SEX", "SAB", "DOM"]  # 0..6

# ---------- READ DELTA -> ARROW -> POLARS ----------
tqdm.write("Lendo Delta (delta-rs) ...")
dt = DeltaTable(DELTA_DIR)
arrow_tbl = dt.to_pyarrow_table()
df = pl.from_arrow(arrow_tbl)

missing = NEEDED_COLS - set(df.columns)
if missing:
    sys.exit(f"Colunas ausentes na Delta: {sorted(missing)}")

# ---------- TYPE CAST ts ----------
tqdm.write("Convertendo 'ts' para datetime e removendo nulos...")
ts_dtype = df.schema["ts"]
if ts_dtype == pl.Utf8:
    # Preferência: str.strptime; fallback para str.to_datetime
    try:
        df = df.with_columns(pl.col("ts").str.strptime(pl.Datetime, strict=False).alias("ts"))
    except Exception:
        df = df.with_columns(pl.col("ts").str.to_datetime(strict=False).alias("ts"))
elif ts_dtype != pl.Datetime:
    df = df.with_columns(pl.col("ts").cast(pl.Datetime).alias("ts"))

df = df.drop_nulls(subset=["ts"])

# ---------- DATA_RELATIVA (vetorizado) ----------
tqdm.write("Gerando DATA_RELATIVA (Polars vetorizado)...")
df = df.with_columns([
    (1 + ((pl.col("ts").dt.ordinal_day() - 1) // 7)).alias("SEMANA_ANO_INICIO_01JAN"),
    pl.col("ts").dt.weekday().alias("WDN"),          # 0..6 (seg..dom)
    pl.col("ts").dt.strftime("%H%M").alias("HHMM"),
])

df = df.with_columns(
    pl.when(pl.col("WDN") == 0).then(pl.lit(WEEKDAY_ABBR[0]))
     .when(pl.col("WDN") == 1).then(pl.lit(WEEKDAY_ABBR[1]))
     .when(pl.col("WDN") == 2).then(pl.lit(WEEKDAY_ABBR[2]))
     .when(pl.col("WDN") == 3).then(pl.lit(WEEKDAY_ABBR[3]))
     .when(pl.col("WDN") == 4).then(pl.lit(WEEKDAY_ABBR[4]))
     .when(pl.col("WDN") == 5).then(pl.lit(WEEKDAY_ABBR[5]))
     .otherwise(pl.lit(WEEKDAY_ABBR[6]))
     .alias("DDD")
)

df = df.with_columns(
    (pl.col("SEMANA_ANO_INICIO_01JAN").cast(pl.Utf8) + pl.col("DDD") + pl.col("HHMM")).alias("DATA_RELATIVA")
)

# ---------- ORDER & SELECT ----------
tqdm.write("Ordenando por 'ts'...")
df = df.sort("ts")

df_out = df.select(["ts", "DATA_RELATIVA", "Q_CTR", "Q_ASS", "Q_COOR", "Q_SPVS", "TURNO"])

# ---------- WRITE PARQUET ----------
tqdm.write("Gravando Parquet (compressão ZSTD)...")
os.makedirs(os.path.dirname(OUT_PARQUET), exist_ok=True)
df_out.write_parquet(OUT_PARQUET, compression="zstd", statistics=True)

tqdm.write(f"OK! Parquet salvo em: {OUT_PARQUET}")
tqdm.write("Amostra das primeiras linhas:")
tqdm.write(df_out.head(8).to_pandas().to_string(index=False))
