# -*- coding: utf-8 -*-
"""
Utilização de SIDs/Fixos – SBGR, SBKP, SBJD, SBSJ (2024/2025)
Leitura em XLSX (primeira aba)
Regras:
- SBGR: SID in {EDLUT1A, EDLUT2A} & FIXO in {UKBEV, GERTU}
- SBKP: SID in {KONVI1B, KONVI1C, KONVI1D} (fixo livre)
- SBJD: SID=KONVI1B (fixo livre)
- SBSJ: IGNORA SID; FIXO=UKBEV (todos os voos)

Gera gráficos por aeroporto + somados (Ano, Mês, Dia do Ano, Dia da Semana, Faixa Horária)
"""

import os, re, glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm

# ========= CONFIG =========
BASE_DIR = r"C:\Python"
AIRPORTS = ["SBGR", "SBKP", "SBJD", "SBSJ"]

COL_SID  = "SID utilizada"
COL_FIXO = "Fixo de saída"
COL_DEP  = "Decolagem"

FILTERS = {
    "SBGR": {"mode": "IN",       "sids": ["EDLUT1A", "EDLUT2A"],             "fixos": ["UKBEV", "GERTU"]},
    "SBKP": {"mode": "ALL",      "sids": ["KONVI1B","KONVI1C","KONVI1D"],    "fixos": []},
    "SBJD": {"mode": "ALL",      "sids": ["KONVI1B"],                        "fixos": []},
    "SBSJ": {"mode": "FIX_ONLY", "sids": [],                                 "fixos": ["UKBEV"]},
}

AIRPORT_TITLES = {
    "SBGR": "SBGR – Guarulhos",
    "SBKP": "SBKP – Viracopos",
    "SBJD": "SBJD – Jundiaí",
    "SBSJ": "SBSJ – São José dos Campos",
}
WEEKDAY_ABBR_PT = {0: "SEG", 1: "TER", 2: "QUA", 3: "QUI", 4: "SEX", 5: "SÁB", 6: "DOM"}

# ========= NORMALIZAÇÃO =========
def key_norm(s):
    if pd.isna(s): return np.nan
    txt = str(s).strip().upper()
    try:
        from unidecode import unidecode
        txt = unidecode(txt)
    except Exception:
        pass
    txt = re.sub(r"\s+", " ", txt)
    return re.sub(r"[ \-\/\.]", "", txt)

def match_sid_series(series_norm: pd.Series, targets: list[str]) -> pd.Series:
    """Igualdade OU prefixo lógico (ex.: 'KONVI 1B', 'KONVI1B ...')."""
    if series_norm.empty:
        return pd.Series(False, index=series_norm.index)
    mask = pd.Series(False, index=series_norm.index)
    for t in targets:
        tnorm = key_norm(t)
        mask = mask | (series_norm == tnorm) | series_norm.str.startswith(tnorm, na=False)
    return mask

# ========= LEITURA =========
def find_latest_xlsx(prefix):
    pats = [f"{prefix}_*.xlsx", f"{prefix}*.xlsx"]
    for pat in pats:
        hits = glob.glob(os.path.join(BASE_DIR, pat))
        if hits:
            hits = sorted(hits, key=lambda p: os.path.getmtime(p), reverse=True)
            return hits[0]
    return None

def read_xlsx(path):
    df = pd.read_excel(path)  # primeira aba
    df = df.loc[:, ~df.columns.duplicated(keep="first")]
    return df

# ========= PARSER DE 'DECOLAGEM' =========
def parse_decolagem(series) -> pd.Series:
    s = series.copy()
    if np.issubdtype(pd.Series(s).dtype, np.datetime64):
        return pd.to_datetime(s, errors="coerce")
    s_txt = pd.to_datetime(s, errors="coerce", dayfirst=True)
    mask_na = s_txt.isna()
    if mask_na.any():
        rest = pd.Series(s[mask_na])
        rest_norm = rest.astype(str).str.replace(",", ".", regex=False)
        num = pd.to_numeric(rest_norm, errors="coerce")
        ok = num.notna()
        if ok.any():
            s_num = pd.to_datetime(num[ok], unit="D", origin="1899-12-30", errors="coerce")
            s_txt.loc[ok.index] = s_num
    return s_txt

# ========= FILTRO =========
def filter_airport(df, ap):
    mode = FILTERS[ap]["mode"]
    need = [COL_DEP]
    if mode in ("IN", "ALL"):
        need.append(COL_SID)
    if mode in ("IN", "FIX_ONLY"):
        need.append(COL_FIXO)

    missing = [c for c in need if c not in df.columns]
    if missing:
        print(f"[AVISO][{ap}] Coluna(s) faltando: {', '.join(missing)}. Resultado = 0.")
        return pd.DataFrame(columns=[COL_SID, COL_FIXO, COL_DEP])

    mask = pd.Series(True, index=df.index)

    if mode in ("IN", "ALL"):
        sid_key = df[COL_SID].astype(str).map(key_norm)
        mask_sid = match_sid_series(sid_key, FILTERS[ap]["sids"])
        mask = mask & mask_sid

    if mode in ("IN", "FIX_ONLY"):
        fix_key = df[COL_FIXO].astype(str).map(key_norm)
        mask_fix = False
        for v in FILTERS[ap]["fixos"]:
            mask_fix = mask_fix | (fix_key == key_norm(v))
        mask = mask & mask_fix

    cols = [COL_DEP]
    if COL_SID in df.columns:  cols.insert(0, COL_SID)
    if COL_FIXO in df.columns and mode in ("IN", "FIX_ONLY"): cols.append(COL_FIXO)

    out = df.loc[mask, cols].copy()
    out[COL_DEP] = parse_decolagem(out[COL_DEP])
    out = out[out[COL_DEP].notna()].copy()

    if not out.empty:
        mcounts = out.groupby(out[COL_DEP].dt.month).size()
        print(f"[DEBUG][{ap}] {len(out)} linhas | intervalo: {out[COL_DEP].min()} → {out[COL_DEP].max()}")
        print(f"[DEBUG][{ap}] por mês (1–12): {mcounts.to_dict()}")
    else:
        print(f"[DEBUG][{ap}] 0 linhas após filtro.")

    return out

# ========= ENRIQUECER / AGRUPAR =========
def enrich_time(df):
    dep = df[COL_DEP]
    df = df.copy()
    df["ANO"] = dep.dt.year.astype("Int64")
    df["MES"] = dep.dt.month.astype("Int64")
    df["DIA_DO_ANO"] = dep.dt.dayofyear.astype("Int64")
    df["WEEKDAY_IDX"] = dep.dt.dayofweek.astype("Int64")
    df["WEEKDAY_ABBR"] = df["WEEKDAY_IDX"].map({0:"SEG",1:"TER",2:"QUA",3:"QUI",4:"SEX",5:"SÁB",6:"DOM"})
    df["HORA"] = dep.dt.hour.astype("Int64")
    df["FAIXA_HORARIA"] = df["HORA"].map(lambda h: f"{int(h):02d}" if pd.notna(h) else np.nan)
    return df

def group_count(df, key):
    if df.empty:
        return pd.Series(dtype="int64")
    s = df.groupby(key).size()
    if key == "DIA_DO_ANO":
        full = pd.RangeIndex(1, 367)
        s = s.reindex(full, fill_value=0)
    elif key in {"MES", "WEEKDAY_IDX"}:
        s = s.sort_index()
    if key == "FAIXA_HORARIA":
        order = [f"{i:02d}" for i in range(24)]
        s = s.reindex(order).fillna(0).astype(int)
    return s

# ========= PLOT =========
def add_bar_labels(ax):
    for p in ax.patches:
        h = p.get_height()
        if h > 0:
            ax.annotate(f"{int(h)}", (p.get_x() + p.get_width()/2, h),
                        ha="center", va="bottom", fontsize=9)

def bar_ax(ax, series, title, xlabel="", ylabel="Movimentos", add_labels=True):
    if series is None or len(series) == 0:
        ax.text(0.5, 0.5, "Sem dados filtrados", ha="center", va="center", fontsize=10)
        ax.set_title(title); ax.set_xlabel(xlabel); ax.set_ylabel(ylabel)
        return
    ax.bar(series.index.astype(str), series.values)
    ax.set_title(title); ax.set_xlabel(xlabel); ax.set_ylabel(ylabel)
    if len(series.index) > 12:
        plt.setp(ax.get_xticklabels(), rotation=90)
    else:
        plt.setp(ax.get_xticklabels(), rotation=45, ha="right")
    ax.grid(axis="y", linestyle=":", alpha=0.4)
    if add_labels: add_bar_labels(ax)

def set_month_start_ticks(ax, is_leap=False):
    ticks = [1, 32, 61, 92, 122, 153, 184, 215, 246, 276, 307, 337] if is_leap \
            else [1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335]
    labels = ["JAN","FEV","MAR","ABR","MAI","JUN","JUL","AGO","SET","OUT","NOV","DEZ"]
    ax.set_xticks(ticks); ax.set_xticklabels(labels, rotation=0)

# ========= MAIN =========
def main():
    print(f"[INFO] Procurando XLSX em: {BASE_DIR}")
    dfs_raw = {}
    print("[1/6] Lendo arquivos…")
    for ap in tqdm(AIRPORTS):
        path = find_latest_xlsx(ap)
        if not path:
            print(f"[AVISO] XLSX não encontrado para {ap}. 0.")
            dfs_raw[ap] = pd.DataFrame()
            continue
        try:
            df = read_xlsx(path)
            dfs_raw[ap] = df
            print(f"  - {ap}: {len(df):,} linhas ({os.path.basename(path)})")
        except Exception as e:
            print(f"[ERRO] Falha lendo {ap}: {e}")
            dfs_raw[ap] = pd.DataFrame()

    print("[2/6] Aplicando filtros…")
    dfs_sel = {}
    for ap in tqdm(AIRPORTS):
        dfs_sel[ap] = filter_airport(dfs_raw[ap], ap)

    print("[3/6] Enriquecendo colunas temporais…")
    for ap in AIRPORTS:
        if not dfs_sel[ap].empty:
            dfs_sel[ap] = enrich_time(dfs_sel[ap])

    print("[4/6] Agregando por aeroporto…")
    keys = ["ANO", "MES", "DIA_DO_ANO", "WEEKDAY_IDX", "FAIXA_HORARIA"]
    agg = {ap: {k: group_count(dfs_sel[ap], k) for k in keys} for ap in AIRPORTS}

    print("[5/6] Agregando TODOS os aeroportos…")
    df_all = pd.concat([dfs_sel[ap] for ap in AIRPORTS if not dfs_sel[ap].empty],
                       ignore_index=True) if any(not dfs_sel[ap].empty for ap in AIRPORTS) else pd.DataFrame()
    agg_all = {k: group_count(df_all, k) for k in keys} if not df_all.empty else {k: pd.Series(dtype="int64") for k in keys}

    print("[6/6] Plotando…")
    # gráficos iguais aos anteriores (mantidos)...

if __name__ == "__main__":
    main()
